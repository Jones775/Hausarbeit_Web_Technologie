\newpage
\section{Resiliente Edge Cloud Systeme in der Praxis} \label{latexDetails}

\subsection{3 Schichten Architektur}

Um Resilienz in Edge Cloud Systemen zu implementieren sind Resiliente Edge Cloud Systeme nach einer 3-Schichten Architektur aufgebaut. Dieses ist am 2-Schichten-Modell eines Software-Defined-Networking Systems angelehnt, 
es wird allerdings um eine zusätzliche Schicht ergänzt. Die unterste Ebene ist die Datenebene. Wie auch in klassischen SDN-Systemen befinden sich auf der Datenebene die Netzwerkgeräte, die den Datenverkehr weiterleiten, 
beispielsweise Router oder Switche. Die mittlere Schicht ist die Kontrollschicht, oder auch Verbindungslogikschicht. Dort wird die Logik definiert, nach der die Geräte der unteren Ebene die Datenpakete weiterleiten sollen. 
Dies wird durch die SDN-Controller durchgeführt. Ein klassisches Netzwerk besteht also aus nur einer Schicht, der Datenschicht. Um eine flexible Anpassung des Netzwerkes zu ermöglichen, 
setzt SDN eine 2-Schichten-Architektur ein, ergänzt also die Kontrollschicht. Um Resilienz in das System zu implementieren ist es logisch, diese 2-Schichten-Architektur wiederum, um eine Schicht zu erweitern. 
Um Resilienz zu gewährleisten, wird auf der mittleren Schicht nicht nur ein SDN-Controller eingesetzt, sondern eine Menge redundanter Controller. Um diese Menge zu koordinieren, wird ein Cluster Manager eingesetzt. 
Dieser ist Teil der dritten und damit höchsten Ebene, der Resilienzmanagementebene. Dieser Controller steuert die große Anzahl an SDN-Controllern.



\subsection{Aufbau eines resilienten Edge Cloud Systems}


Im Verlaufe dieser Arbeit wurden bereits einige Probleme der Resilienz von Edge Cloud Systemen erläutert. Diese 4 Hauptprobleme waren vor allem Kommunikationsabbrüche zwischen Controllern und Netzwerkgeräten, 
Überlastung eines Servers oder einer Verbindung und die Orchestrierung der SDN-Controller. Nun sollen mögliche Lösungen für diese Probleme betrachtet werden, die dazu beitragen können, 
Resilienz in Edge Cloud Systemen zu implementieren. 

Ein großes Problem sind Abbrüche der Verbindung zwischen den SDN-Controllern und den Netzwerkgeräten. Neben Maßnahmen zur Vermeidung eines solchen Abbruches müssen vor allem Regeln definiert werden, 
wie sich die Komponenten im Falle des Abbruchs verhalten sollen. In SDN-Systemen werden Switch häufig mit einer speziellen Software wie OpenvSwitch virtualisiert. 
Eine solche Software stellt für softwarebasierte Switche zwei Funktionsmodi zur Verfügung, also Einstellungen, die definieren, wie sich der Switch verhalten soll. Diese beiden Funktionsmodi sind der secure-Modus, 
sowie der standalone-Modus. Ist bei einem Switch der secure-Modus ausgewählt, so wird dieser nach einer Verbindungstrennung versuchen, sich wieder mit dem zuständigen SDN-Controller zu verbinden. 
Alle einkommenden Pakete verwirft er allerdings. Wie die Bezeichnung also vermuten lässt, ist dieser Modus geeignet, um sicherzustellen, dass kein Paket fälschlicherweise an ein falsches Ziel weitergeleitet wird, 
weil die Flussregeln des Netzwerkgerätes veraltet sind und nicht durch den Controller aktualisiert werden konnten. Bevor dies geschehen kann, reagiert das Netzwerkgerät und stellt seine Tätigkeit ein. 
Der Standalone-Modus ermöglicht ein eigenständiges Handeln des Netzwerkgerätes. Auch hier registriert ein Switch die Verbindungstrennung und versucht sich wieder mit dem zuständigen Controller zu verbinden. 
Die Pakete allerdings verwirft er nicht, sondern sendet sie gemäß seiner Flussregeln weiter. Dies ermöglicht es, dass der Switch eine Zeit lang seine Funktion normal erfüllt, birgt allerdings das Risiko, 
dass sich in der Zwischenzeit die Flussregeln ändern und somit Pakete an einen falschen Empfänger geschickt werden.
Bei diesem Funktionsmodus überwiegen die Vorteile allerdings die Nachteile, sodass dieser Modus in einem resilienten Design gewählt werden sollte. Besonders bei nur kurzen Verbindungsausfällen ist es unwahrscheinlich, 
dass sich Flussregeln zwischenzeitlich ändern. Solche kurzfristen Verbindungsausfälle haben auf den Standalone-Modus nur einen geringen Einfluss, ein Netzwerk, das mit dem Secure-Modus konfiguriert wurde, 
ist allerdings bei jedem Ausfall in seiner Tätigkeit eingeschränkt, weil jene Komponenten des Netzwerkes, die von den Ausfällen betroffen sind ihre Tätigkeit einstellen.


Eine weitere Herausforderung für die Resilienz in Edge Cloud Systemen ist die Überlastung einzelner Server, die bestimmte Services anbieten. Während manche Server kaum genutzt werden, können andere überlastet sein, 
da ihre Services gefragt sind und sie daher zahlreiche Anfragen bearbeiten müssen. SDN-Systeme sind dynamischer als klassische Netzwerke und können daher gut geeignet sein, 
um Mechanismen zur Lastverteilung zu implementieren. Solche Mechanismen helfen bei der Implementierung eines resilienten Edge Cloud Systems. Wichtig ist es zunächst, 
die Kopplung von Software und Hardware so weit wie möglich aufzuheben. Dazu kann Virtualisierung verwendet werden. Die Server einer Serverfarm eines Edge Cloud Systems werden daher virtualisiert, 
so können sie je nach Bedarf erzeugt oder verworfen werden. Dies ermöglicht eine flexible Skalierbarkeit und Anpassbarkeit an die momentane Datenlast. Allein Virtualisierung ist allerdings nicht ausreichend, 
um die Resilienz des Systems gegenüber Datenlast zu steigern. Die einkommende Last muss weitergehend fair auf die vorhandenen virtuellen Server aufgeteilt werden, 
denn eine ungleiche Verteilung führt zu unterschiedlicher Belastung der Server und damit zu nicht notwendigen Wartezeiten. Dieser Verteilung muss innerhalb des Edge-Cloud-Netzwerkes erfolgen, 
kann aber nicht von den Servern selbst durchgeführt werden. Der Client hat keine Kenntnis von der internen Struktur des Edge Cloud Netzwerkes, kann also seine Daten nicht direkt auf die verschiedenen Server adressieren. 
Für diesen muss also eine Möglichkeit bestehen, seine Anfrage an eine zentrale Stelle zu senden, an der diese dann verteilt wird. Auch eine Verteilung bei den Servern ist nicht praktikabel, 
da es sich um virtuelle Server handelt, die nach Belieben aktiviert und deaktiviert werden. Die Verteilung muss daher bei den SDN-Controllern stattfinden, die somit zwischen dem Client, 
also der Quelle der Anfrage und dem Server, also dem Ziel der Anfrage stehen. Die SDN-Controller verteilen die Daten gleichmäßig auf die Server. Dieses Konzept wird mithilfe des Adress Resolution Protocol (ARP) realisiert. 
Das Protokoll dient der Umwandlung von logischen IP-Adressen in physische MAC-Adressen. Dazu wird in einem ARP-Request vom Client aus, eine Anfrage an alle Netzwerkegeräte innerhalb eines Netzwerkes geschickt, 
die die gesuchte IP-Adresse enthält. In einem ARP-Reply schickt das Gerät mit der gesuchten IP-Adresse seine MAC-Adresse zurück an den Client. Nun können beide Geräte über die MAC-Adresse kommunizieren. 
Dieses Protokoll kann man nutzen, um den SDN-Controller als Man-in-the Middle zu etablieren, also einen Zwischenmann, der zwischen Client und Server steht. In der Praxis könnte dies beispielsweise aussehen, 
dass ein Client, der einen Service der Edge Cloud in Anspruch nehmen möchte, einen ARP-Request absetzt, um herauszufinden, wohin er seine Datenpakete schicken soll. 
Dieser ARP-Request wird von einem der SDN-Controller verarbeitet. Dieser ermittelt die Auslastung der virtualisierten Server und entscheidet darauf basierend, welcher Server die Anfrage des Clients bearbeiten soll. 
Dieser virtuelle Server wird automatisch aktiviert. Dem Client schickt der SDN-Controller allerdings nicht die direkte IP-Adresse des virtuellen Servers. Stattdessen schickt er eine virtuelle IP-Adresse, 
die alle Server der Serverfarm repräsentiert. Damit entsteht für den Client der Eindruck, er würde die gesamte Zeit über mit demselben Server kommunizieren, in der Realität kommuniziert er allerdings mit dem SDN-Controller, 
seine Anfragen werden nicht immer vom selben Server bearbeitet, sondern immer von dem, der die höchste Kapazität hat. Für den Client bietet dies den Vorteil, dass er seine Anfrage immer nur an diese IP-Adresse schicken muss, 
der Lastverteilungsmechanismus wird für den Client unsichtbar ausgeführt. Mithilfe dieses Mechanismus lassen sich Edge Cloud Systeme resilienter gestalten, da Schwankungen in der Datenlast häufig zu Überlastung und Wartezeiten führen, was dem Ziel einer möglichst geringen Latenz entgegenläuft. Ein funktionierender Lastverteilungsmechanismus sollte also Teil eine resilienten Edge Cloud Systems sein.

Neben Servern können auch Verbindungen überlastet werden. Das Resultat ist das allerdings das gleiche, es kommt zu langen Wartezeiten und Stau. Im Prinzip folgt die Lösung für dieses Problem dem der Serverüberlastung. 
Statt hier den Datenverkehr zwischen mehreren Servern aufzuteilen, teilt man hier die Daten auf verschiedene Verbindungen auf, um der Überlastung einzelner Verbindungen entgegenzuwirken. 
Das angestrebte Konzept nennt sich Multipath-Routing, also einer Routing-Art, bei der nicht jedes Paket zum selben Ziel zwangsläufig auch denselben Weg nimmt. 
In der klassischen Alternative dem Single-Path Routing ist dies genauso. Zunächst wird dort durch einen Routing-Algorithmus der kürzeste, 
beziehungsweise der schnellste Weg ermittelt und anschließen werden alle Pakete über diesen Weg geleitet. Das führt allerdings dazu, dass dieser Weg schnell überlastet wird, die anderen Verbindungen aber nicht genutzt werden. 
Mit Multi-Path-Routing beugt man dem entgegen, da die Pfadkosten dynamisch den realen Bedingungen im Netzwerk angepasst werden und jedes Paket immer den schnellsten Weg nimmt. Auch wenn das bedeutet, 
dass nicht alle Pakete des Datenstroms dieselbe Verbindung nutzen. Ein solcher Multipath-Routing-Ansatz kann mit Hilfe des OpenFlow Protokolls und der Python-Bibliothek NetworkX realisiert werden. 
OpenFlow stellt Select Groups zur Verfügung. Eine Select Group ist eine Sammlung verschiedener Aktionen, die auf ein Datenpaket angewendet werden können, um es zu seinem Ziel zu leiten. 
Diese einzelnen Aktionen werden Buckets genannt. Ein Bucket hat ein spezifisches Gewicht, also eine Wahrscheinlichkeit, mit der diese Aktion ausgewählt wird. 
Die Gewichte der Buckets werden durch einen Routing-Algorithmus bestimmt, der die Pfadkosten der Netzwerkverbindungen ermittelt. Die zu versendenden Pakete werden gemäß den Gewichten auf die einzelnen Buckets verteilt. 
So bekommen Verbindungen mit hoher Auslastung weniger Pakete zugeteilt als Verbindungen mit niedrigerer Auslastung. Dieser Mechanismus allein sorgt allerdings nur für eine Umverteilung der Pakete. 
Es wird schnell dazu kommen, dass die Alternativverbindungen durch die hohe Zahl der ihnen zugewiesenen Pakete auch überlastet werden, während sich die zuvor überlasteten Verbindungen erholen. 
Um den Datenfluss dauerhaft gleichmäßig zu verteilen, müssen die Pfadkosten kontinuierlich aktualisiert werden. Ziel ist es, dass die Pfadkosten so realistisch wie möglich die realen Bedingungen des Netzwerkes beschreiben. 
Dazu müssen die SDN-Controller regelmäßig Statistiken zur Performance des Netzwerkes von den Switchen abrufen. Ist eine vorher überlastete Verbindung nun weniger ausgelastet, so sinken die Pfadkosten dieser Verbindungen, 
was dann wiederum zu einem höheren Bucket-Gewicht und damit einer wieder steigenden Anzahl an Paketen führt. Im Umkehrschluss führt eine Erhöhung der Auslastung zu höheren Pfadkosten, damit einem niedrigeren Bucket-Gewicht 
und weniger Paketen. Dieser Mechanismus verteilt automatisch den Datenverkehr innerhalb des Netzwerkes und verringert somit das Risiko von überlasteten Verbindungen. Dies bringt außerdem einen weiteren positiven Effekt. 
Innerhalb einer Verbindung konkurrieren verschiedene Datenströme um die Verbindung. In überlasteten Verbindungen kann es daher dazu kommen, dass bestimmte Datenströme einen unfairen Vorteil bekommen. 
UDP-Pakete nutzen beispielsweise die gesamte Bandbreite, die sie benötigen, ohne dabei Rücksicht auf andere Datenströme zu nehmen. TCP-Datenpakete könnten daher in überlasteten Verbindungen von UDP verdrängt werden, 
obwohl sie eigentlich eine höhere Priorität haben könnten. Der Lastverteilungsmechanismus hilft dabei, überlastete Verbindungen zu verhindern und damit auch den unfairen Wettbewerb der Datenströme einzudämmen.

Um die Resilienz zu verbessern, wird das SDN-System nicht nur mit einem SDN-Controller, sondern mit mehreren redundanten Controllern betrieben. Dies bringt eine bessere Skalierbarkeit und Ausfallsicherheit, 
allerdings auch eine Herausforderung mit sich. Die Menge an redundanten SDN-Controllern muss orchestriert und organisiert werden, damit sich die einzelnen Controller nicht gegenseitig behindern. 
Befugnisse und Eingriffsbereiche eines jeden Controllers müssen also zu jedem Zeitpunkt klar definiert sein. Um diese Orchestrierung zu gewährleisten, müssen die Controller verschiedene Rollen annehmen, 
die ihre Einsatzbereiche festlegen. Ein Controller mit der Master-Roller kontrolliert und steuert die ihm zugewiesenen Switche. Er kann außerdem wichtige Protokollnachrichten empfangen, beispielsweise Packet In. 
In einem Cluster kann immer nur ein Controller zum Master werden. Ein Controller, dem die Rolle Slave zugewiesen wurde, überwacht zwar auch das System, erhält allerdings nicht die Protokollnachrichten wie Packet In. 
So fungiert immer nur ein Controller des Netzwerkes als Hauptcontroller. Die Zuweisung der Rollen der Controller erfolgt durch einen Cluster Manager und nach einem festgelegten Verfahren. 
Jeder SDN-Controller des Netzwerkes schickt eine zufällig gewählte Ganzzahl an den Clustermanager. Dieser vergleicht die erhaltenen Nummern nun miteinander. 
Dem Controller mit der niedrigsten Zahl weißt er den ersten Platz in der Reihenfolge, also Platz 0 zu, dem mit der zweitniedrigsten Zahl den zweiten Platz. Dies wird für jeden SDN-Controller durchgeführt, 
bis jeder SDN-Controller eine eindeutige Nummerierung besitzt. Außerdem wird die Gesamtzahl der Controller im Netzwerk abgespeichert. Der Controller mit der höchsten Nummerierung wird zum Master. 
Alternativ können die verschiedenen SDN-Controller die Arbeitslast auch so aufteilen, dass kein zentraler Master notwendig ist, um Nachrichten zu verarbeiten. In diesem Konzept hat jeder Controller die Rolle Equal. 
So ist allerdings ein verteilter Entscheidungsalgorithmus notwendig, der bestimmt, welcher Controller eine eingehende Nachricht verarbeiten soll. In diesem Algorithmus prüft jeder Controller, ob folgende Bedingung zutrifft: 
dpid mod(numbitte unterstrich ergänzenserver) == order. Dpid, also Datapath-Identifier ist die eindeutige Zuordnung eines Switches. Es bezeichnet also, von welchem Switch die einkommende Nachricht gesendet wurde. 
Num_server ist die Gesamtanzahl aller SDN-Controller im System. Order ist die Nummerierung des Controllers, auf dem der Algorithmus jeweils ausgeführt wird. 
Die Modulo Operation teilt also die Menge der Switch auf die Gesamtzahl der Server auf. Ein Controller ist damit immer für die Nachrichten zuständig, die von einem Switch einer bestimmten Gruppe kommen. 
Jeder Controller vergleicht das Ergebnis der Operation mit seiner Nummerierung. Diese Bedingung wird also immer nur bei einem Controller gleichzeitig wahr. Dieser Controller verarbeitet dann die Nachricht. 
Trotzdem ist auch diese Lösung nicht komplett fair, was die Lastverteilung angeht. Kommen von manchen Switchen statistisch öfter Nachrichten, so werden diese auch immer demselben Controller zugewiesen. Um dies zu vermeiden, 
kann man statt nach Switches nach den Nachrichten an sich aufteilen. Dazu muss die Dpid in der Bedingung durch eine eindeutige Nummerierung der ankommenden Nachricht ersetzt werden. 
So wird jede ankommende Nachricht immer einem anderen Controller zugewiesen. Dieser Entscheidungsalgorithmus sorgt für absolut faire Verteilung der zu bearbeitenden Nachrichten auf die einzelnen Controller.






Siehe auch Wissenschaftliches Arbeiten~\footcite[\vglf][S. 1]{Balzert.2008}. %ohne textcommands
Damit sollten alle wichtigen Informationen abgedeckt sein ;-)~\footcite[\vglf][\pagef 1]{Balzert.2008} %mit textcommands
Hier gibt es noch ein Beispiel für ein direktes Zitat\footcite[][\pagef 1]{Balzert.2008} %mit textcommands
TODO das hier sind andere Zitierarten, die bitte entfernen wenn nicht mehr gebraucht






\subsection{Verwendete Software, Editor und Zusatzpakete}
\subsubsection{Windows 8+}
\begin{itemize}
\item MikTex: 2.9, 32-bit
\item Biblatex: 3.5, Zusatz: Biber.exe
\item Editor: TexStudio (kann ich empfehlen), Notepad++
\end{itemize}

\subsubsection{Mac OSX und iOS}
\begin{itemize}
\item MacTeX: \url{https://tug.org/mactex}
\item Editor: TexPad \url{https://www.texpadapp.com}
\end{itemize}

\subsubsection{Online}
Overleaf ist eine Online-Anwendung mit der Ihr direkt im Browser an eurer Thesis schreiben könnt. Bis 1GB Größe und maximal 60 Einzeldateien könnt ihr Overleaf kostenlos nutzen: \url{https://www.overleaf.com/}


\subsection{Dokumentenklasse}
Eigentlich hatte Prof. Finke empfohlen die Dokumentklassen \enquote{Book} oder \enquote{Report} für die Erstellung der Bachelor-Thesis zu verwenden, da diese über weitere Gliederungsebenen verfügen. Ich verwende dennoch eine leicht modifizierte Komaskript-Klasse \enquote{scrartcl}, mit der Erweiterung um eine Ebene. Siehe (skripte/weitereEbene.tex). Das Skript stammt irgendwo aus den Netz und übersteigt meine \LaTeX{}-Fähigkeiten. Dadurch kann ich über eine weitere Ebene in der Arbeit verfügen, ohne mich mit der Modifikation von Kapitel-Seiten rumschlagen~\footcite[Vgl. ][S. 5]{Tanenbaum.2003} zu müssen. Diese Quelle ist nur zur Demonstration und hat keinen inhaltlichen Bezug hierzu. Es werden übrigens nur die Quellen im Literaturverzeichnis angezeigt, die auch referenziert sind.


\subsection{Grafiken}
Das Paket \textbackslash usepackage\{float\} ermöglicht es die Grafiken und Tabellen an der Stelle im Text zu positionieren, wo diese im Quelltext stehen (Option H). Ansonsten würde \LaTeX{} diese dort unterbringen, wo es typographisch sinnvoll wäre - das wollen wir ja nicht ;-).

Die Breite der Grafiken am Besten relativ zum Text angeben.

\subsection{Quellcode}
Quellcode kann auf unterschiedliche Arten eingebaut werden.
Zum einen kann es hier durch direktives Einbinden in der Kapitel-Datei geschehen.
\begin{lstlisting}
% Hier wird aufgezeigt, wie man eine Grafik einbindet, es wird also in der PDF angezeigt,
% da es in einem Quellcode-Listing steht.
% Auch wenn es hier faelschlicherweise als LaTeX-Befehl angezeigt wird.
\includegraphics[width=0.9\textwidth]{sup}
\end{lstlisting}

Bei längeren Quellcode-Listings empfiehlt es sich jedoch auf eine externe Datei im Ordner Quellcode zu verlinken und diese einzubauen:
\lstinputlisting[language=HTML]{./Quellcode/Beispiel.html}

Statt dem Package lstlisting, welches direkt auf Tex basiert, kann auch das Package minted verwendet werden.
Dieses Package basiert auf python-pygments und unterstützt weit mehr Sprachkonstrukte als lstlisting.
Um das Paket zu verwenden muss es eingebunden werden und zusätzlich python-pygments installiert sein.
(Dies ist mit im Dockerfile vorhanden. Für die anderen Compile-Methoden, wie das native verwenden von Tex Live findet sich hier die Installationsanleitung für das minted Paket: https://ctan.org/pkg/minted?lang=de)

Damit das kompilieren ohne Python trotzdem möglich ist, ist die Funktion standardmäßig ausgebaut. Deshalb muss zusätzlich in der Datei \begin{verbatim}thesis_main.tex \usepackage{minted} \end{verbatim} wieder einkommentiert werden. 

Minted lässt sich dann ganz ähnlich zu lstlisting verwenden:
\begin{lstlisting}
	\begin{minted}{c}
		int main() {
			printf("hello, world");
			return 0;
		}
	\end{minted}
\end{lstlisting}	

Da der Pfad zu den Abbildungen im Hauptdokument definiert wurde, muss hier nur noch der Name des Bildes ohne Dateiendung stehen (sup).

\begin{figure}[H]
\caption{Titel der Abbildung hier}
\includegraphics[width=0.9\textwidth]{sup}
\\
Quelle: Eigene Darstellung
\end{figure}

\subsection{Tabellen}
\begin{table}[H]
\caption{Beispieltabelle 1}
\label{tbl:beispieltabelle2}
\begin{tabularx}{\textwidth}[ht]{|l|X|l|}
  \hline
  \textbf{Abkürzung} & \textbf{Beschreibung} & \textbf{Berechnung}\\
  \hline\hline
    MEK & Materialeinzelkosten & \\
  	MGK & Materialgemeinkosten & $+ \uparrow$~*\\
    FEK & Fertigungseinzelkosten & \\
  	FGK & Fertigungsgemeinkosten & $+ \uparrow$~*\\
	SEKF & Sondereinzelkosten der Fertigung & \\
	\hline\hline
	\multicolumn{3}{|l|}{\textbf{= Herstellungskosten}} \\
	\hline\hline
  	VwGK & Verwaltungsgemeinkosten & $+ \uparrow$~*\\
  	VtGK & Vertriebsgemeinkosten & $+ \uparrow$~*\\
  	SEKVt & Sondereinzelkosten des Vertriebes & \\
	\hline\hline
	\multicolumn{3}{|l|}{\textbf{= Selbstkosten}} \\
	\hline\hline
	\multicolumn{3}{|l|}{+ Gewinnaufschlag} \\
	\multicolumn{3}{|l|}{+ Rabatte} \\
	\hline\hline
	\multicolumn{3}{|l|}{\textbf{= Nettoverkaufspreis (NVP)}} \\
	\hline
	\multicolumn{3}{|l|}{+ Umsatzsteuer} \\
	\hline\hline
	\multicolumn{3}{|l|}{\textbf{= Bruttoverkaufspreis (BVP)}} \\
	\hline
\end{tabularx} \\
\cite[Quelle: In Anlehnung an][S. 4]{Beckert.2012}
\end{table}

%\clearpage % hiermit werden alle Bilder Tabellen ausgeworfen

\subsection{Biblatex}
\subsubsection{Erklärung}
Von den vielen verfügbaren Literatur-Paketen habe ich mich für Biblatex entschieden. Die Anforderungen der FOM sollten hiermit erfüllt sein. Ich habe bisher nur Einträge \enquote{@book} getestet. Wie immer steckt der Teufel hier im Detail und es wird sich später herausstellen, ob Biblatex eine gute Wahl war. Die Anpassungen hierfür liegen unter skripte/modsBiblatex. Ich verwende das Backend Biber, welches bib-Dateien in UTF-8 verarbeiten kann.

In der für den Leitfaden 2018 aktualisierten Version sind außerdem Beispiele für \enquote{online},\footcite[Vgl.][]{website:angular:aboutAngular} also Webseiten, und \enquote{article},\footcite[Vgl.][S. 140]{Decker2009} also wissenschaftliche Artikel, enthalten.

Laut Leitfaden sollen maximal 3 Autoren genannt werden und danach mit
\enquote{et. al.} bzw. \enquote{u.a.} ergänzt werden. Damit im Literaturverzeichnis auch nur max.
3 Autoren stehen, muss man beim Füllen der literatur.bib-Datei darauf achten auch nur 3
einzutragen. Weitere Autoren kann man einfach mit \enquote{and others} ergänzen.
Siehe Eintrag für \enquote{Balzert.2008}. Zitiert man dann diese Werk, werden auch in
der Fussnote alle Autoren korrekt genannt wie in dieser
Fußnote\footcite[Vgl.][S. 1]{Balzert.2008} zu sehen ist.

Hat man dagegen mehr als 3 Autoren in der bib-Datei hinterlegt, stehen im
Literaturverzeichnis alle drin. In der Fussnote dagegen, steht nur
einer\footcite[Vgl.][S. 1]{Balzert2.2008}, was dem Leitfaden widerspricht.

Die Anzahl von 3 wird übrigens über die Option \enquote{maxcitenames=3} des
biblatex-Packages gesetzt. Man muss selbst schauen, dass die Anzahl der Autoren
in den Bib-Dateien mit der Optionseinstellung übereinstimmt.

\subsubsection{Beispielfußnoten}
Diese Fussnote soll zeigen, wie mit einem \enquote{von} vor dem Namen des Autors
umgegangen wird\footcite[Vgl.][S. 1]{Lucke2018}. Man muss für die korrekte
Sortierung eines solchens Namens im Literaturverzeichnis einen \enquote{sortkey}
setzen.

Diese Fussnote soll zeigen, wie mit einer Online-Quelle ohne Jahresangabe
umgegangen wird\footcite[Vgl.][]{Belastingdienst}.

Diese Fußnote\footcite[Vgl.][S.1]{Beckert.2012} ist nur dazu da zu zeigen, wie mit mehreren Quellen des selben Autors aus dem selben Jahr umgegangen wird, wenn das Stichwort gleich bleibt \footcite[Vgl.][S.2]{Beckert.2012.1} oder sich ändert\footcite[Vgl.][S.3]{Beckert.2012.2}. Laut Leitfaden sollte bei gleichem Autor, Jahr und Stichwort ein Buchstabe an die Jahreszahl gehangen werden. Zum Beispiel 2012a. 

Die folgenden Fußnoten dienen dazu zu zeigen, dass die Nummern von zwei direkt aufeinanderfolgende Fußnoten mit Komma getrennt werden.\footcite[Vgl.][S.2]{Beckert.2012.1}\footcite[Vgl.][S. 1]{Lucke2018}
\subsection{Abkürzungen}
Abkürzungen werden mithilfe des Pakets Acronym eingebunden. Alle Abkürzungen sollten in der Datei acronyms.tex mithilfe des \begin{verbatim}
	\acro
\end{verbatim} Befehls festgelegt werden. Im Text werden diese dann mit \begin{verbatim}
	\ac{Abkürzung}
\end{verbatim} benutzt. Bei der ersten Verwendung einer Abkürzung wird der Begriff in beiden Formen dargestellt. So wie hier: \ac{WYSIWYG}. Nur wenn eine Abkürzung tatsächlich verwendet wird erscheint sie auch im Abkürzungsverzeichnis.

Sollte es im Abkürzungsverzeichnis zu Anzeigefehlern kommen kann dies daher rühren, dass eine Abkürzung verwendet wird, die länger ist als \ac{WYSIWYG}. In diesem Fall müsst ihr in der Datei acronyms.tex den Parameter [WYSIWYG] durch eure längere Abkürzung ersetzen.

\subsection{Formeln}
Um eine Formel nach links aus zurichten muss sie zwischen \& und \& eingesetzt werden:

\textbf{Formel 1: Erste Formel}
\begin{flalign}
   & L_P{=} 10lg \cdot \frac{P}{1 mW} &
\end{flalign}
\cite[Quelle: In Anlehnung an][S. 4]{Beckert.2012}


Etwas mehr Text.\\
\cite[Quelle: Vgl.][]{FOM}

Ansonsten wird sie mittig ausgerichtet test.
% Mehr infos: http://www.ctex.org/documents/packages/math/amsldoc.pdf

\textbf{Formel 2: Zweite Formel}
\begin{flalign}
   L_P{=} 10lg \cdot \frac{P}{1 mW}
\end{flalign}
\cite[Quelle: In Anlehnung an][S. 4]{Beckert.2012}

\subsection{Symbole}
% die folgenden Symbole haben nicht mit der Formel oben drüber zu tun
Das hier ist ein definiertes Symbol: \symnz und das hier auch \AB . Symbole werden in der Datei Skripte symboldef.tex zentral definiert.

\subsection{Glossar}
Begriffserklärungen bzw. das \gls{glossar} wird mithilfe des Pakets \gls{glossaries} eingebunden. Alle Begriffe die erklärt werden sollen, sollten in der Datei glossar.tex mithilfe des \begin{verbatim}
	\newglossaryentry
\end{verbatim} Befehls festgelegt werden. Im Text werden diese dann mit \begin{verbatim}
	\gls{Begriff}
\end{verbatim} benutzt.


\subsection{Listen und Aufzählungen}
\subsubsection{Listen}
\begin{itemize}
\item ein wichtiger Punkt
\item noch ein wichtiger Punkt
\item und so weiter
\end{itemize}
\subsubsection{Aufzählungen}
\begin{enumerate}
\item Reihenfolge ist hier wichtig
\item Dieser Punkt kommt nach dem ersten
\item Da sollte jetzt eine 3 vorne stehen
\end{enumerate}

\paragraph{Tiefste Ebene 1}
Dies ist die tiefste Gliederungsebene. Sollten doch mehr Ebenen benötigt werden, muss eine andere Dokumentenklasse verwendet werden.

\paragraph{Tiefste Ebene 2}
Der zweite Punkt in dieser Ebene ist zur Erinnerung daran, dass es nie nie niemals nur einen Unterpunkt geben darf.

\subsection{Skript zum Kompilieren}
Latex will ja bekanntlich in einer bestimmten Reihenfolge aufgerufen werden:
\begin{lstlisting}
lualatex thesis_main.tex
biber thesis_main
lualatex thesis_main.tex
lualatex thesis_main.tex
thesis_main.pdf
\end{lstlisting}

Dies ist der Inhalt der Batchdatei \enquote{compile.bat}.

\subsection{PlantUML}

\begin{lstlisting}
\begin{plantuml}
@startuml
Class01 <|-- Class02
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 -- Class10
@enduml
\end{plantuml}
\end{lstlisting}
